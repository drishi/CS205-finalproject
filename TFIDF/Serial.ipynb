{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append(os.path.join('..', 'TFIDF'))\n",
    "sys.path.append(os.path.join('..', 'util'))\n",
    "from timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from HTMLParser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "questions = pickle.load(open(\"lstOfQuestions.pkl\", \"rb\"))\n",
    "questions = questions[:10000]\n",
    "\n",
    "words_dict = {}\n",
    "question_texts = []\n",
    "total = len(questions)\n",
    "count = 0\n",
    "for question in questions :\n",
    "    if count % (total / 10) == 0:\n",
    "        print count\n",
    "    VALID_TAGS = ['p']\n",
    "\n",
    "    soup = BeautifulSoup(question['body'])\n",
    "\n",
    "    VALID_TAGS = ['p']\n",
    "    INVALID_TAGS = ['code', 'a']\n",
    "\n",
    "    text = ' '.join([s.get_text() for s in soup('p')])\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    words = [stemmer.stem(token.encode('ascii', 'ignore').lower()) for token in tokens]\n",
    "\n",
    "    question_texts.append(words)\n",
    "    \n",
    "    for word in words :\n",
    "        if word in words_dict :\n",
    "            words_dict[word] += 1\n",
    "        else :\n",
    "            words_dict[word] = 1\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "id_hash = {}\n",
    "count = 0\n",
    "for question in questions:\n",
    "    if question['question_id'] not in id_hash:\n",
    "        id_hash[question['question_id']] = 1\n",
    "        count += 1\n",
    "\n",
    "print count\n",
    "\n",
    "# Go through dictionary, removing entries that have a value less\n",
    "# than delta\n",
    "delta = 2\n",
    "words_dict2 = {key: value for key, value in words_dict.items()\n",
    "                 if value >= delta }\n",
    "\n",
    "word_indices = {}\n",
    "index = 0\n",
    "for word in words_dict2 :\n",
    "    word_indices[word] = index\n",
    "    index += 1\n",
    "\n",
    "word_indices = list(word_indices.iteritems())\n",
    "\n",
    "output = open('wordIndices_md.pkl', 'wb')\n",
    "pickle.dump(word_indices, output, -1)\n",
    "output.close()\n",
    "\n",
    "output = open('questionTexts_md.pkl', 'wb')\n",
    "pickle.dump(question_texts, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for initialization: 2.86102294922e-06\n",
      "Time for load_questions: 1.90734863281e-06\n",
      "Time for load_indices: 0.016184091568\n",
      "Time for init_tfs: 0.908282995224\n",
      "Time for create_tfs: 1.09990382195\n",
      "Time for create_idf: 1.45337605476\n",
      "Time for calculate_tfidfs: 0.647675991058\n",
      "Time for calculate_simhashes: 85.9166061878\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     tfidf = reload(tfidf)\n",
    "except NameError:\n",
    "    import TFIDF_numpy as tfidf\n",
    "\n",
    "try :\n",
    "    word_indices\n",
    "except NameError:\n",
    "    word_indices = pickle.load(open('wordIndices_md.pkl', 'rb'))\n",
    "\n",
    "try :\n",
    "    question_texts\n",
    "except NameError:\n",
    "    question_texts = pickle.load(open('questionTexts_md.pkl', 'rb'))\n",
    "    \n",
    "tfidf.init_globals()\n",
    "tfidf.load_questions(question_texts)\n",
    "tfidf.load_indices(word_indices)\n",
    "tfidf.init_tfs()\n",
    "serial_tfs = tfidf.create_tfs()\n",
    "serial_idf = tfidf.calculate_idf()\n",
    "serial_tfidfs = tfidf.calculate_tfidfs()\n",
    "# tfidf.calculate_tfidf_norms()\n",
    "# tfidf.calculate_cossim(question_texts[0])\n",
    "serial_simhashes = tfidf.calculate_simhashes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: tfidf_cython_serial.pyx:151:8: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:177:8: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:227:10: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:244:10: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:267:8: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:314:8: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:361:8: Unsigned index type not allowed before OpenMP 3.0\n",
      "warning: tfidf_cython_serial.pyx:383:8: Unsigned index type not allowed before OpenMP 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling with /usr/local/bin/clang-omp\n",
      "Time for Initialization: 0.000407934188843\n",
      "Time for load_questions: 0.0987668037415\n",
      "Time for load_indices: 0.0352869033813\n",
      "Time for init_tfs: 0.829280138016\n",
      "Time for create_tfs: 0.20513677597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: tfidf_cython_serial.pyx:363:17: Use boundscheck(False) for faster access\n",
      "warning: tfidf_cython_serial.pyx:363:47: Use boundscheck(False) for faster access\n",
      "warning: tfidf_cython_serial.pyx:363:64: Use boundscheck(False) for faster access\n",
      "warning: tfidf_cython_serial.pyx:385:17: Use boundscheck(False) for faster access\n",
      "warning: tfidf_cython_serial.pyx:385:47: Use boundscheck(False) for faster access\n",
      "warning: tfidf_cython_serial.pyx:385:64: Use boundscheck(False) for faster access\n",
      "TFIDF_cython.py:76: RuntimeWarning: divide by zero encountered in log\n",
      "  idf = tfidf.calculate_idf(num_keys, locks_ptr, num_locks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for calculate_idf: 0.263386964798\n",
      "Time for int_tfidfs: 0.649344205856\n",
      "Time for calculate_tfidfs: 0.117317199707\n",
      "Time for calculate_simhashes: 0.435800075531\n",
      "Time for calculate distances: 1.36648106575\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    tfidf_c = reload(tfidf_c)\n",
    "except :\n",
    "    import TFIDF_cython as tfidf_c\n",
    "\n",
    "try :\n",
    "    word_indices\n",
    "except NameError:\n",
    "    word_indices = pickle.load(open('wordIndices_sm.pkl', 'rb'))\n",
    "\n",
    "try :\n",
    "    question_texts\n",
    "except NameError:\n",
    "    question_texts = pickle.load(open('questionTexts_sm.pkl', 'rb'))\n",
    "\n",
    "# Preprocess for cython code\n",
    "tfidf_c.init_globals(1, True, \"coarse\", 64)\n",
    "tfidf_c.load_questions(question_texts)\n",
    "tfidf_c.load_indices(word_indices)\n",
    "tfidf_c.init_tfs()\n",
    "cython_tfs = np.asarray(tfidf_c.create_tfs())[:,0:len(word_indices)]\n",
    "cython_idf = np.asarray(tfidf_c.calculate_idf(len(word_indices)))[0:len(word_indices)]\n",
    "tfidf_c.init_tfidfs()\n",
    "cython_tfidfs = np.asarray(tfidf_c.calculate_tfidfs())[:,0:len(word_indices)]\n",
    "cython_simhashes = np.asarray(tfidf_c.calculate_simhashes())\n",
    "cython_distances = tfidf_c.calculate_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "3.05905382673e-05\n",
      "0.000547179457161\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print np.linalg.norm(cython_tfs - serial_tfs)\n",
    "print np.linalg.norm(cython_idf - serial_idf)\n",
    "print np.linalg.norm(cython_tfidfs - serial_tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following are from https://yesteapea.wordpress.com/2013/03/03/counting-the-number-of-set-bits-in-an-integer/\n",
    "def numBits64(i):\n",
    "    i = i - ((i >> np.uint64(1)) & np.uint64(0x5555555555555555))\n",
    "    i = (i & np.uint64(0x3333333333333333)) + ((i >> np.uint64(2)) & np.uint64(0x3333333333333333))\n",
    "    i = ((i + (i >> np.uint64(4))) & np.uint64(0x0F0F0F0F0F0F0F0F))\n",
    "    return (i*(np.uint64(0x0101010101010101)))>>np.uint64(56)\n",
    "\n",
    "def numBits32(i):\n",
    "    i = i - ((i >> 1) & 0x55555555)\n",
    "    i = (i & 0x33333333) + ((i >> 2) & 0x33333333)\n",
    "    i = ((i + (i >> 4)) & 0x0F0F0F0F)\n",
    "    return (i*(0x01010101))>>24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  percent done\n",
      "10.0  percent done\n",
      "20.0  percent done\n",
      "30.0  percent done\n",
      "40.0  percent done\n",
      "50.0  percent done\n",
      "60.0  percent done\n",
      "70.0  percent done\n",
      "80.0  percent done\n",
      "90.0  percent done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: RuntimeWarning: overflow encountered in ulong_scalars\n"
     ]
    }
   ],
   "source": [
    "# distances = [[0 for i in xrange(len(cython_simhashes))] for j in xrange(len(cython_simhashes))]\n",
    "# for i in xrange(len(cython_simhashes)):\n",
    "#     for j in xrange(len(cython_simhashes)):\n",
    "#         distances[i][j] = numBits64(cython_simhashes[i] ^ cython_simhashes[j])\n",
    "#     if i % 1000 == 0:\n",
    "#         print (float(i)/len(cython_simhashes))*100, \" percent done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(metric=\"precomputed\", eps=2, min_samples=3).fit(cython_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9970"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: 1 if x >= 0 else 0, db.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "all_one_labels = []\n",
    "counter = 0\n",
    "for i in xrange(len(db.labels_)):\n",
    "    if db.labels_[i] == -1:\n",
    "        counter += 1\n",
    "    elif db.labels_[i] == 0:\n",
    "        all_one_labels.append(i)\n",
    "print counter\n",
    "print all_one_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have a rail 4.2.3 app where i use devis for user authent . i present my signup form in a bootstrap modal . i have implement it similar to : http : //github.com/plataformatec/devise/wiki/how-to : -display-a-custom-sign_in-form-anywhere-in-your-app . on signup i keep get thi error : and i 'm not sur how to fix it . i use custom control for session and registr . my rout current look like thi : my new user form look like thi - thi get render in a partial that is present in a bootstrap modal : the app crash in my user : :registrationscontrol < devis : :registrationscontrol creat method : and the url in the browser is the follow ( look suspici ! ) : i have tri ad : at the top of my user : :registrationscontrol < devis : :registrationscontrol , but that did n't help . note after run the gem bye bugth app seem to crash in thi method : session [ : previous_url ] return `` /apps/1/edit '' ani idea on what i 'm do wrong here , or anywher els ? sidenot i 'm simultan struggl with anoth devis issu ( they may be relat ) . i have anoth question for that here : rail 4 - devis , guest user caus filter chain halt\n",
      "\n",
      "i am tri to creat an aw lambda function to use for an amazon alexa skill to fetch weather inform from my netatmo weatherst . basic , i need to connect to the netatmo cloud via http request . here 's a snippet of my code , the http request is done for the temporari access token , the request is ok but the result bodi is bodi : { `` error '' : '' invalid_request '' } . what could be the problem here ?\n",
      "\n",
      "i am use a mac and i tri thi php code : i think i 've type a wrong directori , the file exist in 'http : //192.168.1.65/pfe/webservice/connect.php ' , how should i fix my code insid the `` ' `` in order to not get thi error 'unexpect 'require_onc ' ( t_require_onc ) '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in all_one_labels: \n",
    "    print \" \".join(question_texts[i])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
