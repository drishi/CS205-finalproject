{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append(os.path.join('..', 'TFIDF'))\n",
    "sys.path.append(os.path.join('..', 'util'))\n",
    "from timer import Timer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from HTMLParser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "questions = pickle.load(open(\"lstOfQuestions.pkl\", \"rb\"))\n",
    "questions = questions[:20000]\n",
    "\n",
    "words_dict = {}\n",
    "question_texts = []\n",
    "total = len(questions)\n",
    "count = 0\n",
    "for question in questions :\n",
    "    if count % (total / 10) == 0:\n",
    "        print count\n",
    "    VALID_TAGS = ['p']\n",
    "\n",
    "    soup = BeautifulSoup(question['body'])\n",
    "\n",
    "    VALID_TAGS = ['p']\n",
    "    INVALID_TAGS = ['code', 'a']\n",
    "\n",
    "    text = ' '.join([s.get_text() for s in soup('p')])\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    words = [stemmer.stem(token.encode('ascii', 'ignore').lower()) for token in tokens]\n",
    "\n",
    "    question_texts.append(words)\n",
    "    \n",
    "    for word in words :\n",
    "        if word in words_dict :\n",
    "            words_dict[word] += 1\n",
    "        else :\n",
    "            words_dict[word] = 1\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "id_hash = {}\n",
    "count = 0\n",
    "for question in questions:\n",
    "    if question['question_id'] not in id_hash:\n",
    "        id_hash[question['question_id']] = 1\n",
    "        count += 1\n",
    "\n",
    "print count\n",
    "\n",
    "# Go through dictionary, removing entries that have a value less\n",
    "# than delta\n",
    "delta = 2\n",
    "words_dict2 = {key: value for key, value in words_dict.items()\n",
    "                 if value >= delta }\n",
    "\n",
    "word_indices = {}\n",
    "index = 0\n",
    "for word in words_dict2 :\n",
    "    word_indices[word] = index\n",
    "    index += 1\n",
    "\n",
    "word_indices = list(word_indices.iteritems())\n",
    "\n",
    "output = open('wordIndices_sm.pkl', 'wb')\n",
    "pickle.dump(word_indices, output, -1)\n",
    "output.close()\n",
    "\n",
    "output = open('questionTexts_sm.pkl', 'wb')\n",
    "pickle.dump(question_texts, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for initialization: 0.0242218971252\n",
      "Time for load_questions: 1.90734863281e-06\n",
      "Time for load_indices: 0.0130228996277\n",
      "Time for init_tfs: 0.927615880966\n",
      "Time for create_tfs: 1.074021101\n",
      "Time for create_idf: 1.49139118195\n",
      "Time for calculate_tfidfs: 0.655948877335\n",
      "Time for calculate_cossims: 32.8535630703\n",
      "Time for calculate_simhashes: 86.8444750309\n",
      "Time for calculate_distances: 35.4312767982\n",
      "Time for calculate_cossims: 34.7172560692\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     tfidf = reload(tfidf)\n",
    "except NameError:\n",
    "    import TFIDF_numpy as tfidf\n",
    "\n",
    "try :\n",
    "    word_indices\n",
    "except NameError:\n",
    "    word_indices = pickle.load(open('wordIndices_sm.pkl', 'rb'))\n",
    "\n",
    "try :\n",
    "    question_texts\n",
    "except NameError:\n",
    "    question_texts = pickle.load(open('questionTexts_sm.pkl', 'rb'))\n",
    "    \n",
    "tfidf.init_globals()\n",
    "tfidf.load_questions(question_texts)\n",
    "tfidf.load_indices(word_indices)\n",
    "tfidf.init_tfs()\n",
    "serial_tfs = tfidf.create_tfs()\n",
    "serial_idf = tfidf.calculate_idf()\n",
    "serial_tfidfs = tfidf.calculate_tfidfs()\n",
    "# tfidf.calculate_tfidf_norms()\n",
    "serial_cossims = tfidf.calculate_cossims()\n",
    "serial_simhashes = tfidf.calculate_simhashes()\n",
    "serial_distances = tfidf.calculate_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial_cossims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling with /usr/local/bin/clang-omp\n",
      "Time for Initialization: 1.4066696167e-05\n",
      "Time for load_questions: 0.168163061142\n",
      "Time for load_indices: 0.0352330207825\n",
      "Time for init_tfs: 0.671391010284\n",
      "Time for create_tfs: 0.148532867432\n",
      "Time for calculate_idf: 0.202357053757\n",
      "Time for int_tfidfs: 0.612493991852\n",
      "Time for calculate_tfidfs: 0.112776994705\n",
      "Time for calculate_simhashes: 0.349174976349\n",
      "Time for calculate distances: 0.853644132614\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    tfidf_c = reload(tfidf_c)\n",
    "except :\n",
    "    import TFIDF_cython as tfidf_c\n",
    "\n",
    "try :\n",
    "    word_indices\n",
    "except NameError:\n",
    "    word_indices = pickle.load(open('wordIndices_sm.pkl', 'rb'))\n",
    "\n",
    "try :\n",
    "    question_texts\n",
    "except NameError:\n",
    "    question_texts = pickle.load(open('questionTexts_sm.pkl', 'rb'))\n",
    "\n",
    "# Preprocess for cython code\n",
    "tfidf_c.init_globals(1, False, \"coarse\", 64)\n",
    "tfidf_c.load_questions(question_texts)\n",
    "tfidf_c.load_indices(word_indices)\n",
    "tfidf_c.init_tfs()\n",
    "cython_tfs = np.asarray(tfidf_c.create_tfs())[:,0:len(word_indices)]\n",
    "cython_idf = np.asarray(tfidf_c.calculate_idf(len(word_indices)))[0:len(word_indices)]\n",
    "tfidf_c.init_tfidfs()\n",
    "cython_tfidfs = np.asarray(tfidf_c.calculate_tfidfs())[:,0:len(word_indices)]\n",
    "cython_simhashes = np.asarray(tfidf_c.calculate_simhashes())\n",
    "cython_distances = np.asarray(tfidf_c.calculate_distances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "3.05905382673e-05\n",
      "0.000547179457161\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print np.linalg.norm(cython_tfs - serial_tfs)\n",
    "print np.linalg.norm(cython_idf - serial_idf)\n",
    "print np.linalg.norm(cython_tfidfs - serial_tfidfs)\n",
    "print np.linalg.norm(cython_simhashes - serial_simhashes)\n",
    "print np.linalg.norm(cython_distances - serial_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following are from https://yesteapea.wordpress.com/2013/03/03/counting-the-number-of-set-bits-in-an-integer/\n",
    "def numBits64(i):\n",
    "    i = i - ((i >> np.uint64(1)) & np.uint64(0x5555555555555555))\n",
    "    i = (i & np.uint64(0x3333333333333333)) + ((i >> np.uint64(2)) & np.uint64(0x3333333333333333))\n",
    "    i = ((i + (i >> np.uint64(4))) & np.uint64(0x0F0F0F0F0F0F0F0F))\n",
    "    return (i*(np.uint64(0x0101010101010101)))>>np.uint64(56)\n",
    "\n",
    "def numBits32(i):\n",
    "    i = i - ((i >> 1) & 0x55555555)\n",
    "    i = (i & 0x33333333) + ((i >> 2) & 0x33333333)\n",
    "    i = ((i + (i >> 4)) & 0x0F0F0F0F)\n",
    "    return (i*(0x01010101))>>24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([serial_simhashes] * len(serial_simhashes))\n",
    "B = np.copy(A)\n",
    "distances = numBits64(A ^ B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(metric=\"precomputed\", eps=2, min_samples=3).fit(cython_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: 1 if x >= 0 else 0, db.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_one_labels = []\n",
    "counter = 0\n",
    "for i in xrange(len(db.labels_)):\n",
    "    if db.labels_[i] == -1:\n",
    "        counter += 1\n",
    "    elif db.labels_[i] == 4:\n",
    "        all_one_labels.append(i)\n",
    "print counter\n",
    "print all_one_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in all_one_labels: \n",
    "    print \" \".join(question_texts[i])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now doing it for the 32BIT cython distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling with /usr/local/bin/clang-omp\n",
      "Time for Initialization: 1.21593475342e-05\n",
      "Time for load_questions: 0.105110883713\n",
      "Time for load_indices: 0.0522270202637\n",
      "Time for init_tfs: 0.770179986954\n",
      "Time for create_tfs: 0.169428825378\n",
      "Time for calculate_idf: 0.1989839077\n",
      "Time for int_tfidfs: 0.597656011581\n",
      "Time for calculate_tfidfs: 0.11490893364\n",
      "Time for calculate_simhashes: 0.235023021698\n",
      "Time for calculate distances: 1.72152400017\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    tfidf_c = reload(tfidf_c)\n",
    "except :\n",
    "    import TFIDF_cython as tfidf_c\n",
    "\n",
    "try :\n",
    "    word_indices\n",
    "except NameError:\n",
    "    word_indices = pickle.load(open('wordIndices_sm.pkl', 'rb'))\n",
    "\n",
    "try :\n",
    "    question_texts\n",
    "except NameError:\n",
    "    question_texts = pickle.load(open('questionTexts_sm.pkl', 'rb'))\n",
    "\n",
    "# Preprocess for cython code\n",
    "tfidf_c.init_globals(1, False, \"coarse\", 32)\n",
    "tfidf_c.load_questions(question_texts)\n",
    "tfidf_c.load_indices(word_indices)\n",
    "tfidf_c.init_tfs()\n",
    "cython_tfs = np.asarray(tfidf_c.create_tfs())[:,0:len(word_indices)]\n",
    "cython_idf = np.asarray(tfidf_c.calculate_idf(len(word_indices)))[0:len(word_indices)]\n",
    "tfidf_c.init_tfidfs()\n",
    "cython_tfidfs = np.asarray(tfidf_c.calculate_tfidfs())[:,0:len(word_indices)]\n",
    "cython_simhashes = np.asarray(tfidf_c.calculate_simhashes())\n",
    "cython_distances32 = tfidf_c.calculate_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db32 = DBSCAN(metric=\"precomputed\", eps=2, min_samples=3).fit(cython_distances32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: 1 if x >= 0 else 0, db32.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbCossim = DBSCAN(metric=\"precomputed\", eps=0.9, min_samples=3).fit(serial_cossims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: 1 if x >= 0 else 0, dbCossim.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dbCossim.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42025060383200469"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(serial_cossims[0][1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6208851443677339"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(db.labels_, db32.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(dbCossim.labels_, db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.homogeneity_score(dbCossim.labels_, db.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
